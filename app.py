import os
import faiss
import pickle
import torch
import streamlit as st
import numpy as np
from sentence_transformers import SentenceTransformer
from groq import Groq
import google.generativeai as genai

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

client = Groq(api_key='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')
genai.configure(api_key="AIzaSyApnSpZVliqfTKmhfEOu66kczAbsvyPslQ")

# Load embedding model
embedding_model = SentenceTransformer('./saved_Embedding_model')

faiss_directory = "faiss"
faiss_index_file = os.path.join(faiss_directory, "faiss_index.index")
index = faiss.read_index(faiss_index_file)

with open("document_chunks.pkl", "rb") as f:
    document_chunks = pickle.load(f)

def search_with_faiss(query_embedding, index, top_k=10):
    distances, indices = index.search(query_embedding.reshape(1, -1), top_k)
    return [(document_chunks[i], distances[0][j]) for j, i in enumerate(indices[0])]

def ask_groq(query, context):
    messages = [
        {"role": "system", "content": "Báº¡n lÃ  má»™t chuyÃªn gia phÃ¡p luáº­t, dá»±a vÃ o thÃ´ng tin truy xuáº¥t Ä‘Æ°á»£c hÃ£y tráº£ lá»i cÃ¢u há»i. Tráº£ lá»i cá»§a báº¡n cáº§n pháº£i nÃªu Ä‘áº§y Ä‘á»§ vÃ  chÃ­nh xÃ¡c ná»™i dung vá»›i thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p tá»« ChÆ°Æ¡ng, Ä‘iá»u, má»¥c sau Ä‘Ã³ nÃªu cÃ¢u tráº£ lá»i rÃµ rÃ ng. NÃªu cÃ¡c Ä‘iá»u luáº­t liÃªn quan vÃ  ná»™i dung cá»§a Ä‘iá»u Ä‘Ã³ qua cÃ¡c nÄƒm cá»§a cÃ¡c bá»™ luáº­t, Æ°u tiÃªn bá»™ luáº­t má»›i nháº¥t. Diá»…n giáº£i láº¡i cÃ¢u tráº£ lá»i cho ngÆ°á»i dÃ¹ng náº¯m báº¯t tá»‘t nháº¥t. So sÃ¡nh sá»± thay Ä‘á»•i cá»§a bá»™ luáº­t qua cÃ¡c nÄƒm. LÆ°u Ã½ báº¯t buá»™c tráº£ lá»i báº±ng tiáº¿ng Viá»‡t"},
        {"role": "user", "content": f"Context: {context}\nQuestion: {query}"}
    ]
    response = client.chat.completions.create(
        messages=messages, model="llama3-70b-8192"
    )
    return response.choices[0].message.content

def ask_gemini(query, context):
    prompt = f"""
    Báº¡n lÃ  chuyÃªn gia phÃ¡p luáº­t, dá»±a vÃ o thÃ´ng tin Ä‘Ã£ RAG, hÃ£y tráº£ lá»i:
    Context: {context}
    Question: {query}
    - CÃ¢u tráº£ lá»i cá»§a báº¡n cáº§n pháº£i nÃªu Ä‘áº§y Ä‘á»§ vÃ  chÃ­nh xÃ¡c vá»›i thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p tá»« ChÆ°Æ¡ng, Ä‘iá»u, má»¥c sau Ä‘Ã³ nÃªu cÃ¢u tráº£ lá»i rÃµ rÃ ng.
    - NÃªu cÃ¡c Ä‘iá»u luáº­t liÃªn quan vÃ  ná»™i dung cá»§a Ä‘iá»u Ä‘Ã³ qua cÃ¡c nÄƒm cá»§a cÃ¡c bá»™ luáº­t. 
    - TrÃ­ch dáº«n cÃ¡c Ä‘iá»u luáº­t cá»¥ thá»ƒ pháº£i chÃ­nh xÃ¡c theo dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p, Æ°u tiÃªn bá»™ luáº­t má»›i nháº¥t.
    - So sÃ¡nh sá»± thay Ä‘á»•i cá»§a bá»™ luáº­t qua cÃ¡c nÄƒm.
    - Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.
    - Diá»…n giáº£i láº¡i cÃ¢u tráº£ lá»i cho ngÆ°á»i dÃ¹ng náº¯m báº¯t tá»‘t nháº¥t.
    """
    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content(prompt)
    return response.text

st.set_page_config(page_title="Chatbot PhÃ¡p Luáº­t", layout="wide")

if "chat_sessions" not in st.session_state:
    st.session_state.chat_sessions = []

st.sidebar.header("ğŸ“œ Lá»‹ch sá»­ há»™i thoáº¡i")
for i, session in enumerate(st.session_state.chat_sessions):
    if session["conversation"]:
        if st.sidebar.button(f"ğŸ“Œ Há»™i thoáº¡i {i+1}: {session['conversation'][0]['question'][:30]}...", key=f"history_{i}"):
            st.session_state.selected_session = session
            st.sidebar.subheader("CÃ¢u há»i trong há»™i thoáº¡i nÃ y:")
            for q in session["conversation"][-3:]:
                st.sidebar.write(f"- {q['question']}")
    else:
        if st.sidebar.button(f"ğŸ“Œ Há»™i thoáº¡i {i+1}: ChÆ°a cÃ³ cÃ¢u há»i", key=f"history_empty_{i}"):
            st.session_state.selected_session = session

if st.sidebar.button("â• Táº¡o há»™i thoáº¡i má»›i", key="create_new_session"):
    new_session = {
        "conversation": []
    }
    st.session_state.chat_sessions.append(new_session)
    st.session_state.selected_session = new_session 

if st.sidebar.button("ğŸ—‘ï¸ XÃ³a toÃ n bá»™ há»™i thoáº¡i", key="clear_all_sessions"):
    st.session_state.chat_sessions.clear()
    st.session_state.selected_session = None
    st.toast("ğŸ—‘ï¸ ÄÃ£ xoÃ¡ toÃ n bá»™ há»™i thoáº¡i!", icon="âœ…")

st.title("ğŸ’¬ Chatbot Há»— trá»£ PhÃ¡p Luáº­t")


chat_container = st.container()

if "selected_session" in st.session_state and st.session_state.selected_session:
    session = st.session_state.selected_session
    with chat_container:
        for chat in session['conversation']:
            st.chat_message("user").write(chat["question"])
            st.chat_message("assistant").write(f"**ğŸ”· Tráº£ lá»i tá»« Groq:**\n{chat['answer_groq']}")
            st.chat_message("assistant").write(f"**ğŸ”¶ Tráº£ lá»i tá»« Gemini:**\n{chat['answer_gemini']}")


        if st.button("ğŸ—‘ï¸ XÃ³a há»™i thoáº¡i nÃ y"):
            st.session_state.chat_sessions.remove(session)
            st.session_state.selected_session = None
            st.toast("ğŸ—‘ï¸ ÄÃ£ xÃ³a há»™i thoáº¡i nÃ y!", icon="âœ…")

query = st.chat_input("Nháº­p cÃ¢u há»i phÃ¡p luáº­t cá»§a báº¡n...")


if query:
    with st.spinner("ğŸ” Äang tÃ¬m kiáº¿m dá»¯ liá»‡u..."):
        query_embedding = embedding_model.encode(query, convert_to_numpy=True)
        context_chunks = search_with_faiss(query_embedding, index, top_k=5)

    if not context_chunks:
        st.warning("KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p!")
    else:
        context_text = "\n".join([chunk for chunk, _ in context_chunks])

        with st.spinner("Äang táº¡o cÃ¢u tráº£ lá»i..."):
            answer_groq = ask_groq(query, context_text)
            answer_gemini = ask_gemini(query, context_text)

        if "selected_session" not in st.session_state or st.session_state.selected_session is None:
            session = {
                "conversation": [
                    {"question": query, "answer_groq": answer_groq, "answer_gemini": answer_gemini}
                ]
            }
            st.session_state.chat_sessions.append(session)
            st.session_state.selected_session = session
        else:
            st.session_state.selected_session['conversation'].append(
                {"question": query, "answer_groq": answer_groq, "answer_gemini": answer_gemini}
            )

        # Display the answer
        with chat_container:
            st.chat_message("user").write(query)
            st.chat_message("assistant").write(f"**ğŸ”· Tráº£ lá»i tá»« Groq:**\n{answer_groq}")
            st.chat_message("assistant").write(f"**ğŸ”¶ Tráº£ lá»i tá»« Gemini:**\n{answer_gemini}")
